{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "In the lecture we have implemented a few ML models, one using Tensorflow for predicting tomorrow's price the stock mtr (0066.HK).\n",
    "\n",
    "This question asks you to implement yet another ML model using any regression method\n",
    "available in the scikit-learn library, excluding Linear Regression and Neural Networks with\n",
    "the same set of stock price (i.e., 0066.HK between \"2010-\n",
    "01-01\" and \"2020-06-30\"). \n",
    "\n",
    "You should submit a Jupyter notebook that includes the\n",
    "three ML models (i.e., the Tensorflow implementation from the lectures and your\n",
    "implementations using sklearn), and compare their accuracy on predicting the\n",
    "price of 0066.HK during the period \"2021-01-01\" and \"2021-04-30\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reqiurements\n",
    "1. numpy\n",
    "2. pandas\n",
    "3. matplotlib\n",
    "4. scikit-learn\n",
    "5. tensorflow\n",
    "6. akshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pip install akshare\n",
    "import akshare as ak # for getting stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stock data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "symbol = \"00066\"\n",
    "start = \"2010-01-01\"\n",
    "end = \"2020-06-30\"\n",
    "predict_start = \"2021-01-01\"\n",
    "predict_end = \"2021-04-30\"\n",
    "stock_train = ak.stock_hk_hist(symbol=symbol, start_date=start, end_date=end, adjust='') # without adjust\n",
    "stock_predict_actual = ak.stock_hk_hist(symbol=symbol, start_date=predict_start, end_date=predict_end, adjust='') # without adjust\n",
    "\n",
    "# use GradientBoostingRegressor to predict stock price\n",
    "# stock_train columns: 日期/开盘/收盘/最高/最低/成交量/成交额/振幅/涨跌幅/涨跌额/换手率\n",
    "# use close price to predict\n",
    "\n",
    "# add lag and rolling features\n",
    "def create_features(data, lag_days=3, roll_days=3):\n",
    "    for lag in range(1, lag_days + 1):\n",
    "        data[f'lag_{lag}'] = data['收盘'].shift(lag)\n",
    "    data['rolling_mean'] = data['收盘'].rolling(window=roll_days).mean()\n",
    "    data['rolling_std'] = data['收盘'].rolling(window=roll_days).std()\n",
    "    data.dropna(inplace=True)  # drop rows with NaN values\n",
    "    return data\n",
    "\n",
    "# create features\n",
    "stock_train = create_features(stock_train)\n",
    "stock_predict_actual = create_features(stock_predict_actual)\n",
    "\n",
    "# form up X_train, y_train, X_test, y_test\n",
    "X_train = stock_train.drop('收盘', axis=1)\n",
    "y_train = stock_train['收盘']\n",
    "X_test = stock_predict_actual.drop('收盘', axis=1)\n",
    "y_test = stock_predict_actual['收盘']\n",
    "# select only numerical features\n",
    "X_train = X_train.select_dtypes(include=[np.number])\n",
    "X_test = X_test.select_dtypes(include=[np.number])\n",
    "\n",
    "# 定义要比较的模型\n",
    "models = {\n",
    "    'GradientBoosting': GradientBoostingRegressor(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# 定义超参数网格\n",
    "param_grids = {\n",
    "    'GradientBoosting': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [5, 10, None],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 使用 TimeSeriesSplit 进行交叉验证\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 存储结果\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    # 定义管道\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # 定义 GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grids[model_name],\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    # 预测并评估模型\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # 存储结果\n",
    "    results[model_name] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'Best Params': grid_search.best_params_\n",
    "    }\n",
    "\n",
    "    # 打印每个模型的最优参数及评估结果\n",
    "    print(f\"{model_name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} - Optimized MAE: {mae}\")\n",
    "    print(f\"{model_name} - Optimized MSE: {mse}\")\n",
    "    print(f\"{model_name} - Optimized RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# 预测并评估模型\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 存储结果\n",
    "results['LSTM'] = {\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化预测效果 分为2x2分布 4个子图\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.suptitle(f\"Stock Price Prediction for {symbol}.HK\")\n",
    "\n",
    "# 子图1 - GradientBoosting\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "plt.plot(y_test.index, best_models['GradientBoosting'].predict(X_test), label='Predicted', color='red')\n",
    "plt.title(\"GradientBoosting\")\n",
    "plt.legend()\n",
    "\n",
    "# 子图2 - RandomForest\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "plt.plot(y_test.index, best_models['RandomForest'].predict(X_test), label='Predicted', color='yellow')\n",
    "plt.title(\"RandomForest\")\n",
    "plt.legend()\n",
    "\n",
    "# 子图3 - SVR\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "plt.plot(y_test.index, best_models['SVR'].predict(X_test), label='Predicted', color='green')\n",
    "plt.title(\"SVR\")\n",
    "plt.legend()\n",
    "\n",
    "# 子图4 - LSTM\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(y_test.index, y_test, label='Actual', color='blue')\n",
    "plt.plot(y_test.index, y_pred, label='Predicted', color='purple')\n",
    "plt.title(\"LSTM\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出每个模型的MAE, MSE, RMSE\n",
    "metrics_df = pd.DataFrame(results).T\n",
    "metrics_df.plot(kind='bar', figsize=(12, 6))\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Model Comparison - Error Metrics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Choose a suitable method (except neural network) from sklearn to train a\n",
    "Machine Learning model using the MNIST data set for hand-written digit classification.\n",
    "Provide a brief explanation of your chosen method and why it is suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of SVM\n",
    "SVM is a supervised machine learning algorithm used for both classification and regression tasks. In classification, SVM works by finding an optimal hyperplane that best separates the data points of different classes. For linearly separable data, this hyperplane maximizes the margin between the two classes. For data that is not linearly separable, SVM uses a kernel trick to map data into a higher-dimensional space, where it becomes easier to classify with a hyperplane.\n",
    "\n",
    "## Key Reasons Why SVM is Suitable for MNIST\n",
    "1. Effective in High-Dimensional Spaces: MNIST consists of 28x28 pixel images, which translates to a 784-dimensional feature space when each pixel is treated as an individual feature. SVM is known for its effectiveness in handling high-dimensional data.\n",
    "\n",
    "2. Well-Suited for Small to Medium-Size Datasets: While neural networks excel on very large datasets, SVM can perform comparably well on smaller datasets and doesn't require as extensive tuning.\n",
    "\n",
    "3. Ability to Handle Non-Linear Boundaries: With the use of non-linear kernels (e.g., the RBF kernel), SVM can efficiently handle the curved decision boundaries present in complex datasets like MNIST.\n",
    "\n",
    "4. Robustness to Overfitting: By maximizing the margin between classes, SVM tends to generalize well, reducing the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data, mnist.target.astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data to zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the SVM model with RBF kernel\n",
    "svm_model = SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize some predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(1, 11):\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Prediction: {y_pred[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
